# Databricks notebook source
# MAGIC %md
# MAGIC # ü§ñ Model Training & Evaluation - Versi√≥n Simplificada
# MAGIC 
# MAGIC **NOTA IMPORTANTE**: Este notebook requiere un **Databricks Runtime ML** para funcionar completamente.
# MAGIC 
# MAGIC Si ves errores de MLlib, necesitas:
# MAGIC 1. Crear un cluster con Runtime **13.3 LTS ML** (no el est√°ndar)
# MAGIC 2. Conectar este notebook a ese cluster
# MAGIC 
# MAGIC Esta versi√≥n simplificada demuestra el pipeline sin entrenar modelos reales.

# COMMAND ----------

# MAGIC %md
# MAGIC ## ‚ö†Ô∏è Verificar Entorno

# COMMAND ----------

from pyspark.sql import functions as F
from pyspark.sql.types import *
import mlflow

print("‚úÖ PySpark disponible")
print(f"üìä MLflow Tracking URI: {mlflow.get_tracking_uri()}")

# Verificar si MLlib est√° disponible
try:
    from pyspark.ml.regression import RandomForestRegressor
    print("‚úÖ MLlib est√° disponible - Puedes ejecutar el notebook completo")
    MLLIB_OK = True
except Exception as e:
    print(f"\n‚ùå MLlib NO est√° disponible: {e}")
    print("\nüîß SOLUCI√ìN:")
    print("   1. Ve a 'Compute' en Databricks")
    print("   2. Crea un nuevo cluster")
    print("   3. Runtime: 13.3 LTS ML (debe terminar en 'ML')")
    print("   4. Conecta este notebook al nuevo cluster")
    print("\n‚ö†Ô∏è Ejecutando versi√≥n simplificada sin entrenamiento...")
    MLLIB_OK = False

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Cargar Dataset

# COMMAND ----------

spark.sql("USE air_quality_project")
df = spark.table("air_quality_features")

print(f"‚úÖ Dataset cargado: {df.count():,} registros")
print(f"üìã Columnas: {len(df.columns)}")

# COMMAND ----------

display(df.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. An√°lisis Exploratorio

# COMMAND ----------

# Estad√≠sticas de la variable objetivo
print("üìä Estad√≠sticas de PM2.5:")
df.select('pm2_5').describe().show()

print("\nüìä Distribuci√≥n de categor√≠as AQI:")
df.groupBy('aqi_category').count().orderBy(F.desc('count')).show()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Preparaci√≥n de Features

# COMMAND ----------

feature_columns = [
    'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir',
    'hour', 'day_of_week', 'day_of_month', 'week_of_year',
    'is_weekend', 'is_rush_hour', 'is_business_hours',
    'pm25_rolling_3h', 'pm25_rolling_6h', 'pm25_rolling_12h', 'pm25_rolling_24h',
    'temp_rolling_6h', 'temp_rolling_24h',
    'pres_rolling_6h', 'pres_rolling_24h',
    'pm25_lag_1h', 'pm25_lag_3h', 'pm25_lag_6h', 'pm25_lag_12h', 'pm25_lag_24h',
    'temp_lag_6h', 'temp_lag_24h', 'pres_lag_6h',
    'pm25_diff_1h', 'pm25_diff_24h',
    'humidity_ratio', 'temp_pres_interaction', 'temp_deviation', 
    'pm25_trend', 'wind_total',
    'wind_NE', 'wind_NW', 'wind_SE', 'wind_cv',
    'season_Winter', 'season_Spring', 'season_Summer', 'season_Fall'
]

print(f"üìä Features seleccionadas: {len(feature_columns)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Split Temporal

# COMMAND ----------

# Split 80/20 temporal
split_date = df.approxQuantile('timestamp', [0.8], 0.01)[0]

train_df = df.filter(F.col('timestamp') < split_date)
test_df = df.filter(F.col('timestamp') >= split_date)

print(f"üìÖ Fecha de corte: {split_date}")
print(f"‚úÖ Train: {train_df.count():,} registros ({train_df.count()/df.count()*100:.1f}%)")
print(f"‚úÖ Test:  {test_df.count():,} registros ({test_df.count()/df.count()*100:.1f}%)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Modelo Simplificado (Baseline)

# COMMAND ----------

# MAGIC %md
# MAGIC ### Como MLlib no est√° disponible, usamos un modelo baseline simple
# MAGIC 
# MAGIC **Modelo Baseline**: Predecir con el promedio m√≥vil de 24h
# MAGIC 
# MAGIC Este es un buen benchmark para comparar modelos m√°s complejos.

# COMMAND ----------

# Crear predicci√≥n baseline usando rolling average 24h
test_baseline = test_df.withColumn('prediction', F.col('pm25_rolling_24h'))

# Calcular m√©tricas manualmente
from pyspark.sql.functions import sqrt, avg, abs as spark_abs, pow as spark_pow

# RMSE
rmse = test_baseline.select(
    sqrt(avg(spark_pow(F.col('pm2_5') - F.col('prediction'), 2)))
).first()[0]

# MAE
mae = test_baseline.select(
    avg(spark_abs(F.col('pm2_5') - F.col('prediction')))
).first()[0]

# R¬≤ (simplificado)
mean_pm25 = test_baseline.select(avg('pm2_5')).first()[0]
ss_res = test_baseline.select(
    avg(spark_pow(F.col('pm2_5') - F.col('prediction'), 2))
).first()[0]
ss_tot = test_baseline.select(
    avg(spark_pow(F.col('pm2_5') - mean_pm25, 2))
).first()[0]
r2 = 1 - (ss_res / ss_tot)

print("="*70)
print("üìä BASELINE MODEL (Rolling Average 24h)")
print("="*70)
print(f"RMSE: {rmse:.4f}")
print(f"MAE:  {mae:.4f}")
print(f"R¬≤:   {r2:.4f}")
print("="*70)

# COMMAND ----------

# Ver predicciones
display(test_baseline.select('timestamp', 'pm2_5', 'prediction', 'aqi_category').limit(50))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Simulaci√≥n de Experimento MLflow

# COMMAND ----------

# Configurar experimento
mlflow.set_experiment("/Users/shared/air_quality_prediction")

# Registrar modelo baseline en MLflow
with mlflow.start_run(run_name="Baseline_RollingAvg24h") as run:
    
    # Log par√°metros
    mlflow.log_param("model_type", "Baseline_RollingAverage")
    mlflow.log_param("window_hours", 24)
    mlflow.log_param("features_count", 1)
    mlflow.log_param("train_count", train_df.count())
    mlflow.log_param("test_count", test_df.count())
    
    # Log m√©tricas
    mlflow.log_metric("test_rmse", rmse)
    mlflow.log_metric("test_mae", mae)
    mlflow.log_metric("test_r2", r2)
    
    print(f"‚úÖ Experimento baseline registrado: {run.info.run_id}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. An√°lisis de Correlaciones

# COMMAND ----------

# Calcular correlaciones de las top features con PM2.5
correlations = []
for col in ['pm25_lag_1h', 'pm25_lag_24h', 'pm25_rolling_24h', 'TEMP', 'PRES', 'DEWP']:
    if col in df.columns:
        corr = df.stat.corr('pm2_5', col)
        correlations.append((col, corr))

# Ordenar por correlaci√≥n absoluta
correlations.sort(key=lambda x: abs(x[1]), reverse=True)

print("üìä Correlaciones con PM2.5:")
print("-" * 50)
for feat, corr in correlations:
    print(f"{feat:20s}: {corr:7.4f}")
print("-" * 50)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. Guardar Predicciones

# COMMAND ----------

# Guardar predicciones baseline
test_baseline.select(
    'timestamp', 'pm2_5', 'prediction', 'aqi', 'aqi_category'
).write.mode("overwrite").saveAsTable("air_quality_predictions_baseline")

print("‚úÖ Predicciones baseline guardadas")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìã Resumen del Proyecto

# COMMAND ----------

print("="*70)
print("üéâ PROYECTO DE CALIDAD DEL AIRE - RESUMEN")
print("="*70)
print("\n‚úÖ COMPLETADO:")
print("   1. ‚úÖ Data Ingestion (Beijing PM2.5 dataset)")
print("   2. ‚úÖ Data Cleaning (~41,700 registros)")
print("   3. ‚úÖ Feature Engineering (44 features)")
print("   4. ‚úÖ Modelo Baseline (Rolling Average)")
print("   5. ‚úÖ MLflow Tracking (experimento registrado)")
print("\nüìä M√âTRICAS BASELINE:")
print(f"   - RMSE: {rmse:.4f}")
print(f"   - MAE:  {mae:.4f}")
print(f"   - R¬≤:   {r2:.4f}")
print("\n‚ö†Ô∏è PARA COMPLETAR:")
print("   - Cambiar a Databricks Runtime ML")
print("   - Entrenar Random Forest Regressor")
print("   - Entrenar Gradient Boosted Trees")
print("   - Entrenar Random Forest Classifier")
print("   - Comparar con baseline")
print("\nüîß PR√ìXIMOS PASOS:")
print("   1. Crear cluster con Runtime 13.3 LTS ML")
print("   2. Ejecutar notebook 04_model_training_mlflow.py completo")
print("   3. Comparar modelos en MLflow UI")
print("="*70)

# COMMAND ----------

# MAGIC %md
# MAGIC ## üéì Discusi√≥n y Mejoras
# MAGIC 
# MAGIC ### üìä Resultados del Baseline:
# MAGIC 
# MAGIC El modelo baseline (promedio m√≥vil 24h) nos da una referencia importante:
# MAGIC - **RMSE**: Error cuadr√°tico medio - valores bajos son mejores
# MAGIC - **MAE**: Error absoluto medio - m√°s interpretable que RMSE
# MAGIC - **R¬≤**: Proporci√≥n de varianza explicada (0-1, mayor es mejor)
# MAGIC 
# MAGIC ### üéØ Expectativas para Modelos ML:
# MAGIC 
# MAGIC Los modelos de ML (Random Forest, GBT) deber√≠an superar significativamente al baseline:
# MAGIC - **RMSE** esperado: 15-25% mejor que baseline
# MAGIC - **R¬≤** esperado: > 0.85 (baseline t√≠picamente ~0.70-0.75)
# MAGIC 
# MAGIC ### üí° Insights del Dataset:
# MAGIC 
# MAGIC **Variables m√°s importantes (por correlaci√≥n):**
# MAGIC 1. `pm25_lag_1h` - Valor de la hora anterior
# MAGIC 2. `pm25_rolling_24h` - Promedio m√≥vil 24h
# MAGIC 3. `pm25_lag_24h` - Valor del mismo momento ayer
# MAGIC 
# MAGIC Esto confirma que la contaminaci√≥n tiene **fuerte autocorrelaci√≥n temporal**.
# MAGIC 
# MAGIC ### üöÄ Mejoras Propuestas:
# MAGIC 
# MAGIC **1. Modelos M√°s Complejos:**
# MAGIC - XGBoost (mejor que GBT en muchos casos)
# MAGIC - LSTM para series temporales
# MAGIC - Ensemble (combinar m√∫ltiples modelos)
# MAGIC 
# MAGIC **2. Hiperpar√°metros:**
# MAGIC - Grid Search para optimizar par√°metros
# MAGIC - Cross-validation temporal
# MAGIC - Early stopping para evitar overfitting
# MAGIC 
# MAGIC **3. Features Adicionales:**
# MAGIC - Datos de tr√°fico vehicular
# MAGIC - Actividad industrial cercana
# MAGIC - Eventos especiales (festivales, construcci√≥n)
# MAGIC - Features de Fourier para estacionalidad
# MAGIC 
# MAGIC **4. Datos:**
# MAGIC - M√∫ltiples ciudades para generalizaci√≥n
# MAGIC - M√°s a√±os de hist√≥rico
# MAGIC - Validaci√≥n en diferentes contextos
# MAGIC 
# MAGIC **5. Producci√≥n:**
# MAGIC - API REST para predicciones en tiempo real
# MAGIC - Sistema de alertas (AQI > umbral)
# MAGIC - Dashboard interactivo
# MAGIC - Reentrenamiento autom√°tico
# MAGIC 
# MAGIC ### üìà Impacto Esperado:
# MAGIC 
# MAGIC Con modelos ML completos esperamos:
# MAGIC - **Mejora del 20-30%** vs baseline en RMSE
# MAGIC - **R¬≤ > 0.85** (excelente para series temporales)
# MAGIC - **Accuracy > 90%** en clasificaci√≥n de categor√≠as AQI
# MAGIC - **Predicci√≥n √∫til** hasta 6-12 horas adelante
# MAGIC 
# MAGIC ### ‚ö†Ô∏è Limitaciones Actuales:
# MAGIC 
# MAGIC - Solo una ubicaci√≥n (Beijing) - sesgo geogr√°fico
# MAGIC - Periodo limitado (2010-2014)
# MAGIC - No incluye eventos extremos (COVID, olimpiadas)
# MAGIC - Variables meteorol√≥gicas b√°sicas
# MAGIC 
# MAGIC ### ‚úÖ Conclusi√≥n:
# MAGIC 
# MAGIC Este proyecto demuestra un **pipeline completo de ML** para series temporales:
# MAGIC 1. ‚úÖ Ingesta y limpieza robusta
# MAGIC 2. ‚úÖ Feature engineering exhaustivo
# MAGIC 3. ‚úÖ Modelo baseline documentado
# MAGIC 4. ‚úÖ Infraestructura MLflow lista
# MAGIC 5. ‚è≥ Modelos ML pendientes (requiere Runtime ML)
# MAGIC 
# MAGIC **Con Runtime ML, el proyecto alcanzar√° su potencial completo.**
